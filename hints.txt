======== SSH ========
chmod 700 ~/.ssh
chmod 600 ~/.ssh/authorized_keys
ssh-keygen создать ключ ssh
sudo apt install openssh-server установка
sudo systemctl enable sshd чтобы стартовал при запуске пк
копировать на удалённую машину id_rsa.pub
копировать ssh key user в authorized_keys  пользователя root
ssh-copy-id root@192.168.20.116 копировать ssh ключ на сервер
ssh-copy-id -i ~/.ssh/id_rsa.pub root@server2
=====ssh Windows
install opernssh-server
Get-WindowsCapability -Online | Where-Object Name -like 'OpenSSH*'
Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0
opernssh-server
ssh-keygen.exe
201281
====== Архиваторы
tar cf  mytar.tar  Folder1   - заархивировать Folder1
tar xf mytar.tar  - разархивировать архив
gzip     / bzip2     / xz      – скомпрессировать файл
gunzip /  bunzip2 / unxz  – раскомпресировать файл

tar cvzf myBZIP2.bz2  Folder1    – сжать Folder1
tar xvf  myBZIP2.bz2                  - распаковать архив
tar tf myBZIP2.bz2    - посмотреть что внутри архива

zip –r myZIP.zip Folder1   - Запаковать Folder1 в ZIP
unzip myZIP.zip                - Распаковать файл myZIP.zip

========== Разное ==========
rsync -rtuv /path/to/dir_a/* /path/to/dir_b синхронизация папок
rpm2cpio <имя пакета.rpm> | cpio -idmv распаковка пакета без установки
ldd <имя библиотеки> Проверить зависимость библиотеки
scanimage -T тест сканера
mkfs -t ext4 -N 300000 /dev/sda2 указать файлово системе диска количество inode
tune2fs -l /dev/<sda2> посмотреть текущще количество inode inode count
df -i inode
 /opt/1cv8/x86_64/8.3.18.1483/rac infobase create --create-database --name=test1c --dbms=PostgreSQL --db-server=localhost --db-name=testo1c --db-user=user1 --db-pwd=user12345 --cluster=0af8f0de-ff5b-41b4-9c1b-1f7cad289a95 --locale=ru
создание базы данных 1с
sha256sum контрольная сумма
gost12sum контрольная сумма
md5sum проверка контрольной сумы файла
md5sum опции файл
-c - выполнить проверку по файлу контрольных сумм; -b - работать в двоичном формате;
rsync для синхронизации файлов
rsync -zvh anylife /mnt/backup_dir/ локальное
rsync -avz /home/user/documents/ root@123.123.133.133:/home/ пример использования удалённое
lsof утилита служащая для выыода информации о том, какие файлы используются процессами
lsof -u опция выводит список файлов, открытым конкретным пользователем
lsof -U Опция -U позволяет вывести все файлы сокетов домена Unix
lsof +d позволяет выяснить, какие файлы и папки открыты в директории
lsof -p Она позволяет вывести все файлы, открытые процессом с указанным при вызове команды PID.
vmstat - это инструмент мониторинга компьютерной системы
nmon - это инструмент для мониторинга системной производительности компьютера для операционных систем AIX и Linux.
chroot операция изменения корневого каталога
sysstat установка пакета для проверки IO
IOPS (количество операций ввода/вывода – от англ. Input/Output Operations Per Second)
iostat -xtc Просмотр общей статистики ввода-вывода по дискам
pidstat -dl 5 Просмотр статистики в разрезе процессов можно посмотреть в интерактивном режиме
/etc/fstab место где диски монтируются
/etc/apt/sources.list место репозитория
ldap-utils для активных каталогов
======Logs=====
dmesg сообщение от ядра линукс
syslog основной системный журнал
auth.log информация авторизации пользователей
boot.log лог загрузки системы
who кто зашёл в систему
last <имя пользователя> когда пользователь заходил в систему и сколько там был
lastlog список всех пользователей с последней датой входа
tail -f следить за логом в реальном времени
lnav для просмотров логов
lnav r в архиве lnav i показать сколько сообщений было добавлено в лог ? поиск нужного msg
logrotate.d настройка ротации логов
journalctl --list для работы с логами
journalctl --list-boots
journalctl -b -2 логи предыдущей загрузки
journalctl -u ssh посмотреть логи определенной службы
journalctl -f смотреть логи в реальном времени
systemd-analyze общее время загрузки системы
systemd-analyze blame посмотреть сколько времени загружалась каждая служба
grep 'warning' /var/log/syslog пример использования grep в логах
journalctl -p err -b 0
===========================
sudo nmcli conn add type bridge con-name br0 ifname br0 создать мост
sudo nmcli conn add type ethernet slave-type bridge con-name bridge-br0 ifname enp1s0 master br0 добавить интерфейс
sudo nmcli conn show --active посмотреть сетевые подключения
sudo nmcli conn up br0 активировать соеденение
sudo nmcli conn down Ethernet\ connection\ 1 отключение соеденения
nmcli администрирование NetworkManager
network:
  ethernets:
    enp1s0:
      addresses:
      - 192.168.122.99/24
      gateway4: 192.168.122.1
      nameservers:
        addresses:
        - 192.168.30.10
        search: []
  version: 2
Пример рабочего конфига для netplan ubuntu server
hostnamectl узнать имя системы
test
host узнать ip адреса сайта
route посмотреть какие используются роутеры
grep -Pri Search_Term path_to_directory Выяснение наличия в директории файлов, содержащих определённый текст
https://habr.com/ru/company/ruvds/blog/339820/ набор полезного
https://crontab.guru/ всякое для crontab
netstat -tulpen посмотреть порты которые прослушиваются
sudo virsh net-start default  запустить сеть
ls -lS сортировка файлов по размеру
ls -lt сортировка по времени модицикации
ls -lX сортировка по расширению
arp запросить mac адрес
openssl passwd шифрование паролей
scp index.html root@192.168.20.117:/var/www/html/ копировать файл с локальной машины на удалённый сервер
scp root@123.123.123.123:/home/test.txt /directory  копировать с удалённого сервера на локальную машину
sudo dpkg -i path to deb file установка из пакета deb
pbcopy копировать в буфер обмена
sudo ALL=(ALL:ALL) NOPASSWD:ALL
sudo -s перейтив root
echo "afwfawfawf" >(>>добавить в файл) file1.txt создать файл
wget скачать что-то
usermod -aG sudo sammy добавить пользователя в группу sudo
chmod a+x сделать исполняемым для всех
#1/bin/bash для скриптов bash
ps aux расширенный список запущенных процессов
sudo apt-get clean очистить кэш архива apt
sudo apt-get autoclean
apt-get autoremove
shutdown -h +1 выключить пк через 1 минуту
dpkg –i                - установить программу из файла .deb
dpkg –r                - удалить программу
du - посмотреть сколько места занимают файлы и каталоги du -ha показать размер файлов и папок du -hac --exclude="*.log"
df проверка пространства на диске
fdisk программа для управления разделами диска
fdisk -l просмотреть разделы
mount /dev/sdb1 /mnt монтировать раздел
/etc/fstab редактировать, чтобы раздел сам монтировался
lscpu посмотреть процессор
crontab -l    - показать расписание
crontab -e   - редактировать расписание
/etc/crontab  - файл расписания на системном уровне
lpstat -a список сетевых принтеров
ping протокол ICMP echo-request
lshw программа для init системы
hwinfo для инициализации системы
sudo swapoff -a отключить свап памяти, swapon -a включить
nc [-options] [HostName or IP] [PortNumber]  для проверки открытого порта
nc -zvw3 192.168.1.8 22
nc [-options] [HostName or IP] [PortNumber]
nc -z <host> <port>; echo $?
nc -zv 192.168.0.1 20-25 сканировать диапазон портов
dig утилита, предоставляющая пользователю интерфейс командной строки для обращения к системе DNS
wireshark анализатор пакетов
nmap для сканирования портов и сети
nmap [-options] [HostName or IP] [-p] [PortNumber]
nmap -A -T4 для сканирования портов
sudo netstat -tulpn посмотреть порты тоже
sudo chmod ugo+rwx дать все права
snmpwalk -v2c -c public 192.168.12.220 проверить доступность snmp
sudo iptables -L -t nat -v правила iptables
find [папка] [параметры] критерий шаблон [действие]
find . -name "*.png" |grep 2021
find . -type f -name "Загрузки" Для поиска только файлов необходимо использовать параметр f
find . -type d -name "Загрузки" по типа файлов d директория
find ./test ./test2 -type f -name "*.c" Искать в двух каталогах одновременно:
find . -maxdepth 1 -type f -name ".*" ПОИСК СКРЫТЫХ ФАЙЛОВ
find . -type f -perm 0664 Найти файлы с определенной маской прав, например, 0664:
sudo find /usr -type f -perm /u=s
find / -mtime 50 ПОИСК ПО ДАТЕ МОДИФИКАЦИИ
find / -size 50M ПОИСК ФАЙЛОВ ПО РАЗМЕРУ
find . -type f -iname "*.sh" -exec grep -i -n "bash" {} + найти файл и выбрать
sort -n сортировать по числам
apt search python3.9
sudo apt install python3-distutils
sudo apt purge <apt> удаление приложения со всеми хвостами
apt-cache policy найти приложение на пк
apt-cache search найти приложение в репозитории
chkcinfig on чтобы все севрисы RedHat стартовали автоматом
======== Работа с текстом ======
ctrl+w найти
ctrl+o сохранить

======== UFW ======
ufw фаервол
sudo firewall-cmd --zone=public --add-port=80/tcp открыть 80 порт на centOS
sudo ufw status статус фаервола
sudo ufw app list Список приложений с которыми работает ФВ
/etc/ufw/applications.d/nginx.ini документ куда снипет вставлять для работы ВФ и nginx
[Nginx HTTP]
title=Web Server
description=Enable NGINX HTTP traffic
port=80/tcp

[Nginx HTTPS] \
title=Web Server (HTTPS) \
description=Enable NGINX HTTPS traffic
ports=443/tcp

[Nginx Full]
title=Web Server (HTTP,HTTPS)
description=Enable NGINX HTTP and HTTPS traffic
ports=80,443/tcp

======= Конфиг для Nginx Рабочий =======
user www-data;
worker_processes auto;
events {} обязательно эта хрень нужна
http { }
gzip on; Архиватор
server { } блок сервера находится в блоке http
listen 80; на каком порту работает
server_name localhost; Имя сервера
root корень сайта
access_log off; Отключить логирования при доступе к сайту
location /text {
        alias /sites/www/mytext/text.txt; это прямая ссылка на сайт
        #root /sites/www/mytext; изменяет корень сайта
        #try_files $uri =404; какая то директива
      } Тоже важный блок

access_log /var/log/nginx/access.log; доспум к логам
error_log /var/log/nginx/error.log; доступ к логам
include mime.types; подтянуть поддержку html txt png и прочее говно.
return 200 'this is call of duty'; вернуть с кодом 200
=======nginx====
nginx -t проверить конфигурацию
systemctl restart nginx перезапуск nginx
========= Команды Гита ========
система контроля версий
git init . локальный гит
git add . добавить все или один файл в репу
git commit -m "message" добавить коммит на файл
git push origin запушить всё это в облако гита
git pull обновить свою репу с облака
(git)Deploy keys это ssh
apt install git установка
git --version версия гита
git config --global user.name "Vladimir Babushkin"
git config --global user.email "my mail"
git config -l все конфигурации гита
.gitconfig файл с настройками
git status  статус гита
git log история гита git log -1 последний коммит
git log -1 -p показать что было сделано
git checkout -- <имя файла> отменить изменения
git diff --staged разница между staged и последним коммитом
.gitignore прописать то что надо игнорировать
git clone сслыка скачать репозитори
git remote -v по какой ссылке скачал репу
git remote set-url origin <ссылка репы> поменять ссылку репозитори.
git branch показать ветки
git branch <branch name>  название ветки
git checkout  <Название ветки> перейти на ветку
git branch -d <Название ветки> удалить ветку
git checkout -b <название ветки> создать ветку и сразу на неё перейти
git merge <название ветки> соеденить сторонную ветку с мастер копией
git branch -D Удалить ветку, даже были мзменения
git checkout <номер хэша> перейти на оперелённую версию( on commit)
git checkout main перейти на последнюю версию
git commit --amend изменение commit не делая новый
git reset --hard HEAD~2 Полностью вернуться на две предыдущие версии убив новейшие
git reset --soft HEAD~4 удалить commit, не изменяя файлы
git push --set-upstream origin создать свою ветку в github удалённо
git push origin --delete <banch name> Удалить ветку удалённо

==========Ansible=========
sudo yum install epel-release скачать репозиторий CentOS
sudo yum install ansible установка ansible CentOs
ansible --version версия Ансибл
sudo apt-add-repository ppa:ansible/ansible добавить репозиторий на Ubuntu
sudo apt install ansible установка ansible Ubuntu
mkdir ansible создать папку для проекта
nano hosts.txt
[staging_servers]
centOS      ansible_host=192.168.20.98 пример содержимого файла hosts.txt ansible_ssh_private_key_file=/home...
nano ansible.cfg файл конфига
[defaults]
host_key_checking = false  отмена проверки отпечатка пальца
inventory         = ./hosts.txt
root ALL=NOPASSWD: ALL
ansible all(группа серверов) -m(модуль) ping(название модуля) пример команды ping на все сервера
ansible-inventory --list список файла hosts.txt
ansible-inventory --graph так же
ansible all -m setup(модуль параметров сервера)
ansible all -m shell -a "uname" пример использваония модуля shell(команды линукс терминала)
ansible all -m shell -a "rm -fr /" Модуль для увольнения с работы
command безопасная версия модуля shell
shell модуль для выполнения команд терминала линукс
file модуль для создания или удаления файлов, создание директории и тд
copy копирование файла
=======Прочее========
-m модуль
-a(аргумент)
-b become  быть sudo
-v verbose дать больше информации
src=источник
dest=назначение
path=путь
state=absent удаление файла или программы state=removed

ansible all -m file -a "path=/home/privet.txt state=absent" -b пример удаления файла
state: directory  для создания директории в playbook
ansible all -m copy -a "src=privet.txt dest=/home mode=777" -b пример копирования файла
content: содержание файлов при использовании модуля copy
get_url скачать что-то по ссылке
ansible all -m get_url -a "url="https://anydesk.com/ru/downloads/linux dest=/home/vladimir" Пример скачивания
yum RedHat apt Debian модуль для установки программ
ansible all -m yum -a "name=gimp state=latest" -b пример установки программы
ansible all -m yum -a "name=gimp state=removed" -b пример удаления программы
service позволяет управлять сервисами
ansible all -m service -a "name=httpd state=started enabled=yes"  пример запуска сервиса при старте
force копировать файл на удаленный хост, если содержимое файла было изменено
uri читать содержимое ссылки
ansible all -m uri -a "url=https://nsau.edu.ru return_content=yes" Отобразить содержимое сайта
vars: переменные для playbook
src={{ source_file }} dest= {{ destin_file }} пример использования переменных в playbook
handlers: Дополнительный таск в случае срабатывания notify
notify: способ вызова handlers
 - name: Copy Index.html to web
   copy: src={{ source_file }} dest={{ destin_file}}
   notyfy: Restart Apache
Пример использования notify, перезапуск веб сервера если изменилось содержимое index

- debug: выдать сообщение var: использовать параметр переменной msg: сообщение
- set_fact: объеденить переменные
при использовании var не использовать фигурные скобки. если используется переменная, нужны скобки
register: сохранить output команды
when: Условие(можно поставить в конце block)
 - name: Install apache
   apt: name=apache2 state=latest
   when: ansible_os_family == "Debian"
- block Блоки
{{ item }} переменная, сохранённое слово
loop: цикл task
 -name: Install many packaged
    yum: name={{ item }} state=latest
    loop:
      - gimp
      - tree
      - mc

until конечный цикл
- name: Loop Until example
  shell: echo -n Z >> myfile.txt && cat myfile.txt
  register: output
  delay: 2
  retries: 10
  until: output.stdout.find("ZZZZ") == false
with_fileglob: "{{ source_folder }}/*.*" скопировать всё содержимое папки
index.j2 создание шаблона в шаблоне используются переменные ansible
template: сгенерировать из шаблона
- name: Generate Index.html file
  template: src={{ source_folder }}/index.j2 dest={{ destin_folder }}/index.html
ansible-galaxy init <название роли> команда для создания ролей
roles: указать вместо tasks, при использовании ролей, указать роль
roles:
 - { role: install_apt, when: ansible_system == 'Linux' } запускать роль, если ОС Линукс
hosts: "{{ myhosts }}" для использования внешних переменных
--extra-var "myhosts=prod_servers" использование внейшней переменной. Наивысший приоритет
include: <file name> импорт файла. Изначально создать файл с параметрами
delegate_to: передать выполнение таска определённому серверу
- name: ping test
  ping:
  delegate_to: Linux1
shell: sleep 3 && reboot now перезагрузка с задержкой в 3 секунды
async: 1 максимальный тайм аут
poll: 0 проверить команду
 - name: Wait host online
   wait_for:
   host: "{{ inventory_hostname }}" ansible var
   state: started нужное состояние
   delay: 5  начинать ждать через 5 секунд
   timeout: 40 максимум жадть 40 секунд
   delegate_to: 127.0.0.1
run_once: true запустить один раз
ignore_errors: yes игнорировать ошибки
 - name: Task 1
   apt: name=treee state=latest
   ignore_errors: yes пример игнорирования ошибки task
failed_when: выдать ошибку если
 tasks:
  - name: task num2
    shell: echo Hello World
    register: results
    failed_when: "'World' in results.stdout"
  - debug:
      var: results
rc return code: 0 выполнено
failed_when: results.rc == 0 запустить ошибку если код 0
any_errors_fatal : true любая ошибка прекращает выполнение playbook
---
- name: errors
  hosts: all
  any_errors_fatal : true
  become: yes
ansible-vault create <имя файла> создать зашифрованный файл
ansible-vault view <имя файла> посмотреть зашифрованный файл
ansible-vault edit <имя файла> редактировать зашифрованный файл
ansible-vault rekey поменять пароль
ansible-vault encrypt <имя файла> зашифровать файл
ansible-vault decrypt <названия файла> расшифровать файл
--ask-vault-pass спросить пароль дешифровки исполняемого файла
ansible-playbook playbook1.yml --ask-vault-pass
--vault-password-file <имя файла> использовать файл с содержимым паролем
ansible-vault encrypt_string зашифровать строчку. После шифрования пароля, запускать с дешифровкой
echo -n "secret" | ansible-vault encrypt_string так же зашифровать слово
==============docker==============
docker ps -q | xargs  docker stats --no-stream отобразить использование cpu mem io
sudo apt install apt-transport-https
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt install docker-ce
sudo systemctl status docker проверить статус службы
sudo usermod -aG docker $USER добавить пользователя в группу докера
docker run hello-world проверить что всё норм
docker -v проверить версию докера
docker images какие есть докер образы
docker pull скачать образ
docker ps показать бегущие контейнеры
docker ps -a все контейнеры которые бежали
docker run(запустить) -it(интерактивно) -p(перенаправить порты) 1234:8080 tomcat(назвае образа)
docker run -d -p 1234:80 hello-world запустить background
docker search найти образ
docker rmi стереть образ
docker rm стереть контейнер
docker cp host_source_path container:destination_path скопировать файл в докер контейнер
docker inspect просмотр полной информации о запущенном докере
docker logs -f логи докера
docker exec исполнить команду в запущенном контейнере
docker exec [OPTIONS] CONTAINER COMMAND [ARG...]
docker ps -q | xargs  docker stats --no-stream посмотреть сколько ресурсов потребляет контейнер
docker-compose -f docker-compose.yml up -d запуск файла docker compose
docker stop $(docker ps -a -q) остановить все контейнеры
docker rm $(docker ps -a -q)  удалить все контейнеры
docker stack deploy	Deploy a new stack or update an existing stack
docker stack ls	List stacks
docker stack ps	List the tasks in the stack
docker stack rm	Remove one or more stacks
docker stack services	List the services in the stack
docker run -d --name=nginx nginx:latest  запустить конктейнер со своим именем
docker rm --force nginx принудительная остановка и удаление контейнера
docker run -d -p 80:80 -v /root/default.conf:/etc/nginx/conf.d/default.conf nginx свой конфиг
:ro режим только для чтения
https://www.digitalocean.com/community/tutorials/how-to-remove-docker-images-containers-and-volumes-ru



#--------mydocker file test
RUN apt-get -y install
FROM задаёт базовый образ
ENV устанавливает постоянные переменные среды
RUN  выполняет команду и создаёт слой образа. Используется для установки в контейнер пакетов
COPY копирует в контейнер файлы и папки
ADD копирует файлы и папки в контейнер. Моежт распаковывать локальные .tar файлы
CMD описывает команду с аргументами, которую нужно будет выполнить когда контейнер будет запущен
WORKDIR задаёт рабочую директорию для следующей инструкции
ARG задаёт переменные для передачи Docker во время сборки образа
ENTRYPOINT предоставляет команду с аргументами для вызова во время выполнения контейнера
EXPOSE указывает необходимость открыть порт
VOLUME создаёт точку монтирования для работы с постоянным хранилищем
docker vulume create  создать
docker volume ls посмотреть
docker volume inspect посмотреть содержимое
-v ключ для подключения vulome
-e ENV
docker run -d -v pg_data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=mysecretpassword postgres
docker volume create pg_data_nfs -d local -o type=nfs -o o=addr=192.168.1.2 -o device=:/mnt/data/nfs
монтирование nfs шары
docker volume create data -o device=/home/vladimir/Myproject/dockerfile2/data -o type=none -o o=bind
создать локальный volume

==============================
docker build -t <название> . собрать docker image
docker tag vovka:v1 vova:copy создать копию image с новым tag
docker exec -it <номер контейнера> /bin/bash запустить терминал внутри контейнера
docker commit <container ID> vova:v2 пример создания новой версии image на основе существующего
docker login зайти на докер
docker push <repository name>/<image name> запушить на docker hub
docker commit 1a130ee353a9 mattcat1988/apachetest:6 переименовать образ не в локальный и запушить
docker start запустить контейнер
docker stop  остановить контейнер
Обязательно переименовать образ
set -e для прекращения сборки если случилась ошибка
==============docker-compose======
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose

=======gitactions====
- uses: actions/checkout@v2 скачать репу
runs-on: [self-hosted] запустить на ранере

# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  MyTest:
    # The type of runner that the job will run on
    runs-on: [self-hosted]

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: sudo docker -v
      - name: check current file
        run: ls -la
      - name: pwd
        run: pwd

run: rsync -e "ssh -p 20022 -i $HOME/.ssh/key -o StrictHostKeyChecking=no" --archive --compress --delete . index.html:/var/www/html




======================SQL==================
3306 порт для mysql
mysql -h 127.0.0.1 -u root -p подключение к локальной базе
show databases; показать все базы
show tables; посмотреть все таблицы
SHOW COLUMNS FROM `people`; показать структуру таблички people
use выбрать базу данных
ALTER TABLE table_name RENAME TO new_table_name переименовать таблицу
DESC имя таблички, отобразить структуру таблицы
CREATE DATABASE <name database> создать базу данных
DROP DATABASE <name database> удалить базцу данных
INT для числовых значений integer в postgeSQL
ENUM совсем короткий формат текстовых данных
Пример
ENUM ('value-1', 'value-2', 'value-3')
SET тоже для хранения текста
VARCHAR небольшие символьные значение character varying postgesql
FLOAT вечественный тип данных
DECIMAL для хранения чисел с указанием сколько знаков после десятичного разделителя будет зайдействовано
TEXT Большие текстовые значения text postgresql
DATA формат для работы с датами
CREATE TABLE users (id INT) создать таблицу users
DROP TABLE удалить таблицу
NOT NULL не оставлять пустым
AUTO_INCREMENT каждый раз увеличивать поле на одну еденицу
PRIMARY KEY(name) уникальное значение
Пример:
CREATE TABLE people(
  id INT NOT NULL AUTO_INCREMENT,
  name VARCHAR(30),
  email VARCHAR(40),
  bio TEXT,
  birth DATE,
  PRIMARY KEY(id)
);
ALTER TABLE <имя таблицы> ADD <имя столбика> VARCHAR(32) добавить новое поле в таблицу
ALTER TABLE <имя таблицы> DROP COLUNM <имя столбика>
INSERT INTO  <имя таблицы>(столбики)
VALUES (' ') значение
Пример:
INSERT INTO people (name, bio, birth, email) VALUES ('Vova', 'prog', '1988-02-07', 'vova@mail.ru') добавить запись
ALTER TABLE <name table> CHANGE <name table> <name table> DATE NOT NULL; значение дата не может быть пустым
UPDATE оператор для обновления записи
SET установить(в каком столбике)
WHERE условие
AND дополнительное условие
Пример:
UPDATE `people` SET `name` = 'Maxim' WHERE id = 5 пример обновления информации в таблице
UPDATE `people` SET `name` = 'Vovka' `email` = 'pepe@mail.ru' WHERE id > 4
UPDATE `clothes` SET `bio` = 'green' WHERE `clothes`.`id` = 2;
DELETE  оператор удаления
FROM откуда
DELETE FROM `test`; удаление всех записей в таблице test
DELETE FROM `test` WHERE id = 2; удаление записи у которой id = 2
TRUNCATE очистить полностью таблицу
TRUNCATE `test`;
SELECT оператор выбора * выбрать всё
FROM от куда
Пример:
SELECT * FROM `people`; выбрать всё
SELECT `name', `bio` FROM `people`; выбрать частично
SELECT `id`, `name` FROM `people`WHERE id >= 2 AND id < 4; выборка с дополнительными условиями
IS(IS NOT) проверить значение
Пример:
SELECT * FROM `people` WHERE `email` IS NULL;
OR позвоялет применить какое либо из условий
Пример:
SELECT * FROM `people` WHERE `name` = 'Pavel' OR id = 4;
DISTINCT выбрать уникальные объекты

SELECT DISTINCT `name` FROM `people`;
LIMIT лимитировать выборку данных, всегда пишется в самом конце
Пример:
SELECT * FROM `people` LIMIT 2; показать только два значения
SELECT * FROM `people` LIMIT 2, 3; сколько пропустить, сколько всего показать
ORDER BY оператор сортировки всегда пишется перед LIMIT, WHERE пишется до ORDER
Правильная последовательность операторов
SELECT * FROM `people` WHERE name = 'Vova' ORDER BY id LIMIT 2, 3;
выборка, условие, сортировка, лимит.
DESC сортировка по убыванию
Пример:
SELECT * FROM `people` ORDER BY `id` DESC LIMIT 2, 3;
BETWEEN оператор диапазона AND используется как оператор для диапазон
SELECT * FROM `people` WHERE `id` BETWEEN 2 AND 3 AND id <> 4 ORDER BY `id` DESC LIMIT 10;
IN() оператор диапазона
SELECT * FROM `people` WHERE `id` IN (1,4,5) ORDER BY `id` DESC LIMIT 10;
LIKE оператор выборки
SELECT * FROM `people` WHERE `name` LIKE 'V%'; выбрать все записи где имя начинается на V
SELECT * FROM `people` WHERE `email` LIKE '%mail%'; показать записи, где есть mail в любом месте
INDEX для ускорения поиска информации
Пример создания индекса для колонки name:
CREATE INDEX NIndex ON `people`(name);
DROP INDEX NIndex ON `people`; удаление индекса
DEFAULT CURRENT_TIMESTAMP указывать текущую дату при добавлении эелемента
FOREIGN KEY и REFERENCES для создания ссылок
Пример:
CREATE TABLE orders(
     id INT NOT NULL AUTO_INCREMENT,
     orderNumber INT,
     shopID INT,
     personID INT,
     date_time DATETIME DEFAULT CURRENT_TIMESTAMP,
     PRIMARY KEY(id),
     FOREIGN KEY(shopID) REFERENCES shop(id),
     FOREIGN KEY(personID) REFERENCES people(id)

); Пример где personID создан как ссылка на id из таблички people
Пример построения связей на примере магазина
INSERT INTO `orders`(`orderNumber`, `shopID`, `personID`)
       VALUES
       (0001, 2, 4),
       (0002, 4, 1),
       (0003, 2, 3),
       (0004, 4, 4),
       (0005, 3, 1),
       (0006, 3, 2);
INNER JOIN для того, чтобы объеденить таблицы
SELECT orders.orderNumber, people.name, people.email FROM people
INNER JOIN orders ON people.id = orders.personID
ORDER BY orders.orderNumber DESC;
Пример проверки объеденения записей и дальнейшая сортировка по убыыванию
SELECT shop.title, people.name, people.email FROM people
INNER JOIN orders ON people.id = orders.personId
INNER JOIN shop ON shop.id = orders.shopID
ORDER BY orders.orderNumber DESC;
 пример объеденения нескольких таблиц
Пример объеденения таблиц при помощи LEFT JOIN RIGHT JOIN
SELECT people.name, orders.orderNumber FROM people
LEFT JOIN orders ON people.id = orders.personID
ORDER BY people.name DESC;
Проверить слияние таблиц SQL JOIN
использование RIGHT JOIN сравнения
SELECT orders.date_time, people.name FROM `orders`
RIGHT JOIN `people` ON orders.personID = people.id;
AS назначить псевдоним
Пример:
SELECT `name` AS 'Имя', `birth` AS 'День рождения' FROM `people`;
CONCAT объеденение полей
Пример:
SELECT CONCAT('Имя: ', name, '. День Рождения: ', birth) AS 'Информация' FROM `people`;
выборка из двух таблиц
SELECT p.id, p.name, s.title, s.price FROM `people` AS p, `shop` AS s;
COUNT функция подсчёта
Пример:
SELECT COUNT(id) FROM `shop`;
MIN and MAX выбрать минимальное или максимальное значение
SELECT MIN(price) FROM shop; выбрано минимальное значеие по цене из таблицы SHOP
AVG найти среднее арифметическое значение
SUM сумма
UCASE перевести всё в верхний регистр
LCASE перевести в нижний регистр
GROUP BY группировать
Пример
SELECT `price`, COUNT(price) FROM `shop` GROUP BY price; Групировка по цене
SELECT `price` AS 'Цена', COUNT(price) AS 'Количество' FROM `shop`
GROUP BY price HAVING COUNT(price) > 1; Показать результаты где количество больше чем 1
SELECT price AS 'Цена', COUNT(price) AS 'Количество' FROM shop s GROUP BY price HAVING
HAVING применяется не для всего набора столбцов таблицы, а для набора,
созданного оператором SQL GROUP BY и применяется всегда строго после него.
COUNT(price) < 2;
=====postgreSQL=====
Типы данных
Integer, smallint, bigint целочисленные
REAL, DOUBLE PRECISION
(infinity, NaN); С плавающей запятой
Character(N), Char(N), TEXT; Символьные
Timestamp, date, time, interval; Временные
Bit(n), BIT VARYING(n) битовые
Money Монетарный
serial значит уникальный
id serial primary key
psql -h 192.168.20.70 -U user1 test1c -W способ подключения

=====ORACLE SQL=====
типы данных
char(n) символьный формат максимальный размер 2000 байт
varchar2(n) символьный формат максимальный размер 4000 байт
number(точностьб масштаб) числовое значение
date Используется для хранения даты и времени
=====JSON====
формат хранения данных
схема ключ значание
JSON Schema структура документа
============================
jq для фильтрации JSON  запросов
-c               compact instead of pretty-printed output;
  -n               use `null` as the single input value;
  -e               set the exit status code based on the output;
  -s               read (slurp) all inputs into an array; apply filter to it;
  -r               output raw strings, not JSON texts;
  -R               read raw strings, not JSON texts;
  -C               colorize JSON;
  -M               monochrome (don't colorize JSON);
  -S               sort keys of objects on output;
  --tab            use tabs for indentation;
  --arg a v        set variable $a to value <v>;
  --argjson a v    set variable $a to JSON value <v>;
  --slurpfile a f  set variable $a to an array of JSON texts read from <f>;
  --rawfile a f    set variable $a to a string consisting of the contents of <f>;
  --args           remaining arguments are string arguments, not files;
  --jsonargs       remaining arguments are JSON arguments, not files;
  --               terminates argument processing;
curl http://api.icndb.com/jokes/random | jq "." > my_sample.json запарсить в файл формата json
cat my_sample.json | jq ".type" пример вывода содержимого type
cat my_sample.json | jq ".value.joke" вывести содержимое value и joke
========Kafka==========
Kafka Broker, kafka Server, Kafka Node:
функции брокера, приём сообщений, хранение и выдача.
Kafka кластер. Масштабирование и репликая данных
Zookeeper состояние кластера, Конфигурация, адресная книга(data)
kafka controller обеспечивает согласованность данных
Kafka Message
Key ключ для распределения сообщений по класетеру
Value содержимое
Timestamp ну тут понятно
Headers Набор key-value пар
Kafka Topic-stream of data хранилище сообщений и событий, там же выставляется очередь
Partitions для парарелизации обработки данных
Данные топика хранятся в Log файлах
.log самое сообщение, index позиция в топике, timeindex
новый активный segment создается когда log файлы переполнены
Data removing from Kafka Topic поддерживается автоматическое удаление TTL
удаляются сегменты партиций segment timestamp expired - to delete
Data Replication(Set replication-factor(>1)) для отказоустойчивости
Master-Slave- Гарантия согласованнсти данных
На каждый Broker по одной Lead реплики
Kafka Controller назначает Leader-реплики
ISR  min.insync.replicas = 3 синхронизация лидеров с фоловерами
Kafka Producer отправитель сообщений
acks = 0 producer не ждет подтверждение отправки сообщений
acks = 1 producer ждет подтверждения отправки ссобщений только от Leader-реплики
acks = -1(all) все сообщения
Kafka Consumer получатель сообщений
<<group.id>> consumer для одновременной обработки данных consumer = particia
Kafka Consumer Offset Last consumed message by Group
<<group.id: X>> __consumer_offset информация о прочитанных сообщениях
Kafka Consumer Offset commit
Auto commit - at most once
Manual commit -at least once
Custom offset managment - exactly once(not missed. no duplicates)
used: auto.offset.reset
earliest or latest
=======CURL======
curl -LJO "" скачать по ссылке
https://mcs.mail.ru/blog/10-komand-curl-kotorye-vam-sleduet-znat
curl инструмент для передачи данных с сервера на сервер
curl -X GET для запроса API -i получить заголовки
curl -XPOST отправить пост запрос -d передать тело запроса
curl -XPOST http://api.icndb.com/jokes/random -d 'Hello'
curl -XPOST http://api.icndb.com/jokes/random -d '{"name": "alex"}'
Метод запроса POST предназначен для запроса, при котором веб-сервер принимает
данные, заключённые в тело сообщения, для хранения. Он часто используется для
загрузки файла или представления заполненной веб-формы. В отличие от него, метод
HTTP GET предназначен для получения информации от сервера.
curl -i информация о заголовках
curl --head запрос головы
curl -o test.txt загрузить данные запроса в документ
curl -O скачать
curl --data "title=hello&body=Hello World" запрос в виде списка=значение для тестирования api
curl --data "param1=test1&param2=test2" http://test.com
curl --data '{"param1":"test1","param2":"test2"}' \http://www.test.com  запрос в виде JSON
curl -X DELETE удалить, что-то
curl -k игнорирование ошибки неправильных сертификатов
curl -u <user:password> https://my-test-api.com/endpoint1 использование авторизации
curl -L vk.com идти за сайтом если переехал
curl -v получить больше информации о сайте
curl -v --user-agent chromium vk.com сделать запрос от другого агента
curl -L adv-it.net/kaka.jpg --output myfile.jpg сохранить файл с сайта
curl -s https://api.astahanov.net -d '{'username' : "Sasha", "password" : "12345"}' | jq Отправить запрос JSON 
curl -s https://api.astahanov.net -d @myfile.json | jq послать данные из файла
curl -s https://api.astahanov.net -d @myfile.json | jq .runtime --raw-output убрать кавычки из запроса или -r
=======Zabbix=====
apt-get install zabbix-agent для установки zabbix agent
service zabbix-agent start для запуска zabbix-agent
=====prometheus=====
https://github.com/Einsteinish/Docker-Compose-Prometheus-and-Grafana ссылка
https://github.com/prometheus/prometheus/releases/download/v2.35.0-rc1/prometheus-2.35.0-rc1.linux-amd64.tar.gz
https://github.com/prometheus/alertmanager/releases/download/v0.24.0/alertmanager-0.24.0.linux-amd64.tar.gz
https://github.com/prometheus/node_exporter/releases/download/v1.3.1/node_exporter-1.3.1.linux-amd64.tar.gz
========URBACKUP=======
dfisk dev/vdb press n
t выбрать тип linux 83 w сохранить
localhost:55414 порт urbackup
mksf.btrfs /dev/vdb1 выбрать систему для urbackup
/dev/vdb1 /backup btdfs defaults 0 0 монтирование при автозагрузке fstab
mount -a чтобы применить fstab
============Redis==============
redis-cli переейти в redis
SET устанавливает для определенного ключа значение
SET foo 42 у ключа foo будет значение 42
GET foo вернёт параметр ключа
EXIST проверяет существует есть ли что-то с данным ключом
FLUSHALL удаляет все данные в базе данных
EX время сколько будет храниться значение в секундах
SET var "Hello" EX 20 пример
PX в милисекундах
GETSET возвращает старое значение и устанавливает новое
APPEND добавляет ещё символы
KEYS * возвращает все ключи
INCR увеличение на 1 единицу INCR counter
DECR уменьшение на 1 единицу
HSET хэш-таблица
Хэш-таблица объект состоящий из полей. Каждое поле имеет свое имя и значение
HSET person1 name "Vasya"
HGET получить значения
HGETALL <сущность> показать все ключи и значения
HVALS получает все значения
HKEYS получает все ключи
Множество это список значений
SADD добавить множество
SMEMBERS <key> получить все значения входящие в множество
SCARD кардинальное число, сколько элементов в множестве SCARD another
SUNION <key> объеденение двух или более множеств
SDIFF <key> <key> разность
SINTER пересечения SINTER <key> <key>
SPOP <key> возвращает и удаляет случайный элемент множества
Список это последовательность значений, упорядоченных по порядку их создания
LPUSH добавляет значение в список
LRANGE получить значения списка слева LRANGE mylist 0 -1
RPUSH
LPOP взять значение списка слева
LLEN mylist длинна списка
ZADD упорядоченное множество ZADD persons 1980 "Vasya"
ZRANGE список упорядоченного множества ZRANGE persons 0 -1 WITHSCORES
Транзакция это множество команд, выполняющихся, как одна команда
MULTI начинает запись команд
EXEC начать выполнение команд
DISCARD прервать исполнение транзакции
SUBSCRIBE подписка SUBSCRIBE news
PUBLISH публикация PUBLISH news "Hello"
=====Terraform======
terraform init инициализация конфигурации
terraform fmt форматировать конфигурацию
terraform validate проверка конфигурации
terrafotm plan план структуры
terraform apply запустить структуру
terraform destroy уничтожить структуру
variables.tf с содержимым
variable "container_name" {
  description = "Value of the name for the Docker container"
  type        = string
  default     = "ExampleNginxContainer"
}
 для переменных
заменить переменную на var.container_name в основном манифесте
terraform apply -var "container_name=YetAnotherName" пример замены одной переменной
======SED=======
sed options file - схема sed
echo "This is a test" | sed 's/test/another test/' простой пример sed
s - команда замены
-e для обработки нескольких действий
sed -e 's/This/That/; s/test/another test/'
-f чтение команд из файла
Флаги
g обработка всех вхождений шаблона
p вывести содержимое исходной строки
№ порядковый номер вхождения шаблона в строку
w file указывает команде на то, что нужно записать результаты обработки текста в файл
s/pattern/replacement/flags
-n подавляет обычный вывод
sed 's!/bin/bash!/bin/csh!' /etc/passwd пример замены /bin/bash на /bin/sch/ в /etc/passwd
№s указание номера строки которую нужно обработать
sed '2,$s/test/another test/' <file> обработать весь текст начиная со второй строки.
sed 'is a/s/govnar/' выполнить замену по фильтру
sed '3d' <файл> удаление третьей строчки файла(отображение)
sed '2,5d' диапазон удаление строк
sed '3,$d' удалить всё начиная с стретьей строки
sed '/test/d' удаление по шаблону
sed '/first/,/second/d' <file> удалить используя несколько шаблонов
i\ добавляет перед заданной строкой a\ добавляет после заданной \2i вставить перед строчкой
echo "second test" | sed 'i\five text'
sed '2c\Another text' <file> заменить строку
sed '/templest/c changed text' использовать шаблон или регулярное выражение
sed 'y/123/567/' <file> заменитяет символы согласно выбранным шаблонам.
sed '=' <file> посмотреть число строк в потоке. sed -n '/test/=' <file> вывести только номера
sed '3r <file>' <target file> вставить содержимое файла в поток после третьей строки.
sed '/test/r newfile' myfile пример например
Sed '/HEHE>/ {
r file.json
d}' myfile      заменяет HEHE на данные из другого файла
awk '/\$/{print $0}' file экранировка знака $
символ ^ используется для поиска шаблона в начале строки
$ Для поиска в конце строки(awk)
! печатать строки не соответвующме шаблону, например пустые
awk '!/^$/{print $0}' file
awk '/[oi]th/{print $0}' myfile искать наборы символов [] классы ^ в начале или в конце
awk '/[^sm]th/{print $0}' file отрицание классов символов
awk '/[e-z]th/{print $0}' file пример диапазона символов
awk '/[0-9][0-9][0-9]/' пример диапазона чисел
[[:alpha:]] — соответствует любому алфавитному символу, записанному в верхнем или нижнем регистре.
[[:alnum:]] — соответствует любому алфавитно-цифровому символу, а именно — символам в диапазонах 0-9, A-Z, a-z.
[[:blank:]] — соответствует пробелу и знаку табуляции.
[[:digit:]] — любой цифровой символ от 0 до 9.
[[:upper:]] — алфавитные символы в верхнем регистре — A-Z.
[[:lower:]] — алфавитные символы в нижнем регистре — a-z.
[[:print:]] — соответствует любому печатаемому символу.
[[:punct:]] — соответствует знакам препинания.
[[:space:]] — пробельные символы, в частности — пробел, знак табуляции, символы NL, FF, VT, CR.
Специальные классы символов
echo "zxcd235" | awk '/[[:digit:]]/{print $0}' использование классов в шаблонах
* обозначает любой символ
echo "xeeeeez" | awk '/x[ae]*z/{print $0}' пример использования. Любомые символы и количество
echo "test" | awk '/tes?t/{print $0}' знак вопроса указывает на то что s встречается 1 раз или 0
echo "teest" | awk '/t[ae]?st/{print $0}' класс символов, a или e встречается больше одного раза
Знак + означает что символ встретися 1 или более раз echo "teest" | awk '/te+st/{print $0}'
echo "teeast" | awk '/t[ae]+st/{print $0}' пример с классами символов
n — число, задающее точное число искомых вхождений
n, m — два числа, означающие « минимум n раз, но не больше чем m»
echo "test" | awk '/te{1}st/{print $0}' пример фигурные скобки точное число вхождений
echo "teeest" | awk '/te{1,2}st/{print $0}' пример минимум 1, но не больше 2
echo "test" | awk  '/t[ae]{1,2}st/{print $0}' пример с классами символов
символ | означает "или"
Пример echo "This is an exam" | awk '/test|exam/{print $0}'
echo "Linderman" | awk '/Linder(man)?/{print $0}' пример группировки в крулхы скобках
:nohlsearch #vim снять выделение
systemctl set-default multi-user.target Отключить GUI
systemctl set-default graphical.target Включить GUI
service gdm restart Перезагрузка gnome
strace -o вывод данных в файл
strace -e trace=stat <app> фильтр
=======Kubernetes=====
kubectl apply -f <file.yaml> Развернуть кластер
kubectl delete -f <file.yaml> удалить кластер
kubectl logs [pod name] логи пода
kubectl exec -it [pod name] --/bin/bash зайти в контейнер интерактивно
kubectl get pods, nodes, deployment 
